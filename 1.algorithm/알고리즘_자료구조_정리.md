# 알고리즘 & 자료구조 관련 정리

## DP

- 조건

  - 최적 부분 구조
    - 부분 문제들의 최적의 답을 이용하면 전체 문제의 최적의 답이 구해지는 구조
  - 중복되는 부분 문제

- 활용

  - 한 번 계산한 결과를 재활용하는 것
  - Memoization
    - 하향식 방법
    - 딕셔너리 cache를 활용하여 재귀로 구현
  - Tabulation
    - 상향식 방법
    - 상향식이기 때문에 문제를 푸는 데 필요없는 부분도 미리 계산하는 경우도 있다. 그래서 Memoization에 비해 약간의 비효율 발생할 수도 있다

- 예시

  - ```python
    def max_profit(stock_list):
        result = stock_list[1] - stock_list[0]
        min_buy_value = stock_list[0]
        
        for i in range(len(stock_list)-1):
            if stock_list[i] < min_buy_value:
                min_buy_value = stock_list[i]
            
            profit = stock_list[i+1] - min_buy_value
            if profit > result:
                result = profit
                
        return result
    
    
    # 테스트
    print(max_profit([7, 1, 5, 3, 6, 4]))
    print(max_profit([7, 6, 4, 3, 1]))
    print(max_profit([11, 13, 9, 13, 20, 14, 19, 12, 19, 13]))
    print(max_profit([12, 4, 11, 18, 17, 19, 1, 19, 14, 13, 7, 15, 10, 1, 3, 6]))
    ```

  - ```python
    def sublist_max(profits):
        result = profits[0]
        cur_max = profits[0]
        
        for i in range(1, len(profits)):
            cur_max = max(cur_max + profits[i], profits[i])
            result = max(result, cur_max)
                    
        return result
    
    
    # 테스트
    print(sublist_max([7, -3, 4, -8]))
    print(sublist_max([-2, -3, 4, -1, -2, 1, 5, -3, -1]))
    ```

  - ```python
    def trapping_rain(buildings):
        width = len(buildings)
        lefts = [0 for _ in range(width)]
        rights = [0 for _ in range(width)]
        
        for i in range(1, width):
            if lefts[i-1] < buildings[i-1]:
                lefts[i] = buildings[i-1]
            else:
                lefts[i] = lefts[i-1]
            
        for i in range(width-2, -1, -1):
            if rights[i+1] < buildings[i+1]:
                rights[i] = buildings[i+1]
            else:
                rights[i] = rights[i+1]
        
        # for left in lefts:
        #     print(left, end=' ')
            
        # print()
        
        # for right in rights:
        #     print(right, end=' ')
        
        # print()
        
        waters = 0    
        for i in range(1, width-1):
            if buildings[i] < lefts[i] and buildings[i] < rights[i]:
                waters += min(lefts[i], rights[i]) - buildings[i]
                
        return waters
    
        
    # 테스트
    print(trapping_rain([3, 0, 0, 2, 0, 4]))
    print(trapping_rain([0, 1, 0, 2, 1, 0, 1, 3, 2, 1, 2, 1]))
    ```



## Greedy Algorithm

- 최적의 답을 구할 수 있는 조건
  - 최적 부분 구조
  - 탐욕적 선택 속성
    - 최적 부분 구조와 다른 점은 시점에 있다. 탐욕적 선택 속성은 지금 당장 목표를 달성하기 위해 탐욕적으로 선택하면, 그 선택이 결과적으로도 최선의 선택일 때를 의미한다



## Sorting

### Merge Sort

```python
## 모범 답안
def merge(list1, list2):
    i = 0
    j = 0

    # 정렬된 항목들을 담을 리스트
    merged_list = []

    # list1과 list2를 돌면서 merged_list에 항목 정렬
    while i < len(list1) and j < len(list2):
        if list1[i] > list2[j]:
            merged_list.append(list2[j])
            j += 1
        else:
            merged_list.append(list1[i])
            i += 1

    # list2에 남은 항목이 있으면 정렬 리스트에 추가
    if i == len(list1):
        merged_list += list2[j:]

    # list1에 남은 항목이 있으면 정렬 리스트에 추가
    elif j == len(list2):
        merged_list += list1[i:]

    return merged_list


def merge_sort(my_list):
    # base case
    if len(my_list) < 2:
        return my_list

    # my_list를 반씩 나눈다(divide)
    left_half = my_list[:len(my_list)//2]    # 왼쪽 반
    right_half = my_list[len(my_list)//2:]   # 오른쪽 반

    # merge_sort 함수를 재귀적으로 호출하여 부분 문제 해결(conquer)하고,
    # merge 함수로 정렬된 두 리스트를 합쳐(combine)준다
    return merge(merge_sort(left_half), merge_sort(right_half))
```

```python
## 내가 짠 것. merge 과정과 쪼개는 과정을 합쳐놔서 가독성 떨어짐
def merge(list1, list2):
    if len(list1) == 0:
        return list2
    elif len(list2) == 0:
        return list1
    
    mid_list1 = len(list1) // 2
    mid_list2 = len(list2) // 2
    
    sorted_list1 = merge(list1[0:mid_list1], list1[mid_list1:])
    sorted_list2 = merge(list2[0:mid_list2], list2[mid_list2:])
    
    result_list = []
    while True:
        if len(sorted_list1) == 0:
            result_list += sorted_list2
            break
        elif len(sorted_list2) == 0:
            result_list += sorted_list1
            break
        
        if sorted_list1[0] <= sorted_list2[0]:
            result_list.append(sorted_list1.pop(0))
        else:
            result_list.append(sorted_list2.pop(0))
            
    return result_list

# 합병 정렬
def merge_sort(my_list):
    mid = len(my_list) // 2
    return merge(my_list[0:mid], my_list[mid:])
```



### Quick Sort

```python
# 두 요소의 위치를 바꿔주는 helper function
def swap_elements(my_list, index1, index2):
    my_list[index1], my_list[index2] = my_list[index2], my_list[index1]
    return


# 퀵 정렬에서 사용되는 partition 함수
def partition(my_list, start, end):
    p = end
    b = start
    i = start
    
    while i != p:
        if my_list[i] > my_list[p]:
            i += 1
            continue
        else:
            swap_elements(my_list, b, i)
            i += 1
            b += 1
            
    swap_elements(my_list, b, p)
    
    return b


def quicksort(my_list, start=0, end=None):
    if end == None:
        end = len(my_list) - 1
    
    if start == end:
        return
    
    p = partition(my_list, start, end)
    quicksort(my_list, start, p-1)
    quicksort(my_list, p, end)
    
    return
```



## 자료구조

- `x in 자료구조` 할 때, list보다 set이 훨씬 빠름
  - 이유?



### 배열(Array)

- list가 여러 타입의 값을 담을 수 있는 이유
  - list의 값이 사실 레퍼런스이기 때문에 실제 데이터가 몇 바이트를 차지하는지 관계 없음
  - C 배열에서는 값에 실제 값들이 들어가야 하기때문에 몇 바이트를 차지해야하는지 선언해주고 시작해야함. 그래서 다른 타입은 담기 어렵기 때문에 C의 배열은 다른 타입을 금지한다
- 동적 배열(ex: list)의 append 연산은 최악의 경우 O(n) 이지만 **분할 상환 분석**을 하면 O(1)이다. 즉 생각보다 아주 비효율적인 것은 아니다라는 것을 의미하는 듯. 내부적으로 처음부터 메모리를 넉넉히 생성해놓기 때문. 따라서 매번 정적 배열 생성해서 값 복사하는 것은 아니니까
  - 반대로 동적 배열의 맨 끝 데이터 삭제 연산도 최악의 경우 O(n) 이지만 **분할 상환 분석**을 하면 O(1)이다. 매번 정적 배열 생성해서 값 복사한 후 메모리 공간을 줄이는 건 아니니까



### 연결 리스트(Linked List)

- `Node` 라는 클래스를 만들고 해당 인스턴스 변수를 `data`, `next` 로 만들어 둔다
- `LinkedList` 라는 클래스를 만들고 `append`, `insert`, `delete` 등 메소드를 만들어 준다. 메소드를 만드는 과정에서 `Node` 클래스의 인스턴스를 생성해서 사용하면 된다



### 해시 테이블(Hash Table)

- 개념
  - 고정된 크기의 배열을 만든다
  - 해시 함수를 이용해서 key를 원하는 범위의 자연수로 바꾼다
    - 해시 함수의 조건
      - 어떤 수를 넣던지 항상 같은 값이 나와야 한다(결정론적이어야 한다)
      - 결과 값이 나오는 확률이 비슷해야 한다
      - 계산이 빨라야 한다(효율적이어야 한다)
  - 해시 함수 결과를 인덱스로 하여, 배열에 key-value 쌍을 저장한다
- Python hash 함수
  - `hash()`: 기본적으로 내장된 hash 함수
  - 파라미터로 받은 값을 특정 범위 안에 있는 정수가 아닌 아무 정수로 바꿔준다
  - 불변 타입 자료형만 파라미터로 받을 수 있다
    - 불린형, 정수형, 소수형, 튜플, 문자열 등
- 해시 테이블 충돌
  - hash 함수를 사용하면 공역이 정의역보다 작기 때문에 다른 파라미터를 넣어도 hash 값이 같을 수 있다. 이를 hash 충돌이라 한다
  - 이를 극복하기 위한 방법 중 하나가 Chaining 이다
    - 배열에 key-value 쌍을 저장할 때 연결 리스트 Node 방식으로 저장하고, 충돌이 날 때마다 이어서 사용하는 것이다. 그러면 같은 hash 값을 가져도 충돌을 극복할 수 있다
  - Open Addressing 방식을 충돌을 극복할 수도 있다
    - 빈 주소에 충돌난 key-value를 저장하는 방식이다
    - Open Address를 찾는 방식은 여러 가지다. 선형 탐사 방식은 충돌난 주소에서부터 한 칸씩 뒤에 있는 인덱스를 넣어보며 빈 주소를 찾는 방식이다. 제곱 탐사 방식은 k^2 (k는 자연수) 뒤에 있는 인덱스를 넣어보며 빈 주소를 찾는 방식이다
    - Open Addressing 방식에서 데이터를 삭제할 때, 그냥 삭제해버리면 안되고 따로 데이터가 삭제되었다는 표시를 해주어야 한다. 왜냐면 해시 충돌이 일어났을 때 탐사 규칙에 따라 탐색을 하게되는데, 중간에 있는 데이터를 그냥 삭제해버리면 그 공간은 원래 데이터가 없는 곳으로 인식된다. 따라서 해당 삭제 공간 이후에 저장된 해시 충돌 데이터를 탐색할 수 없고 데이터가 삭제된 공간에 삭제 표시를 해줘야 계속 모든 데이터를 탐색할 수 있다
- Chaining 방식을 사용하는 해시 테이블의 시간 복잡도
  - 해시 테이블을 사용하는 연산들의 주요 부분 단계
    - 해시 함수 계산, 배열 인덱스 접근, 링크드 리스트 탐색 + (수정, 삽입, 삭제 등의 연산)
    - 이 중 링크드 리스트 탐색 과정이 많은 시간을 소요한다. 최악의 경우 모든 데이터들이 한 배열 인덱스에 저장될 수도 있으니까
  - 최악의 경우(key-value 데이터 들이 모두 해시 충돌이 나는 경우)에는 시간 복잡도가 O(n)
  - 하지만 이런 경우는 드문 경우이다. 동적 배열에서 시간 복잡도를 합리적으로 계산하기 위해 분할 상환 분석 방식을 택했던 것처럼, 해시 테이블에서도 평균 시간 복잡도 방식을 생각해보는 것도 합리적이다
    - hash 함수는 되도록 결과 값이 비슷한 확률로 나오도록 하는 것이 원칙이다. 따라서 key-value 데이터 쌍의 갯수를 n, 배열의 크기를 m 이라 할 때 링크드 리스트의 평균 길이는 n/m 이다
    - 이 경우에 n과 m의 크기를 비슷하게 조절해준다면, 링크드 리스트 탐색에 드는 시간 복잡도는 O(1) 이라고 할 수 있다
    - 따라서 평균 시간 복잡도 방식을 생각해본다면, 해시 테이블의 시간 복잡도는 O(1)이라 생각할 수도 있다. 하지만 역시 최악의 경우는 O(n) 이다
- Open Addressing 방식을 사용하는 해시 테이블의 시간 복잡도
  - Open Addressing 방식도 Chaining 방식처럼 최악의 경우(해시 테이블의 거의 꽉 찼을 경우) 시간 복잡도는 O(n)이다
  - 하지만 해시 테이블이 꽉차 있는 경우는 거의 없고, load factor α = n/m (n은 해시 테이블 안에 들어 있는 데이터 key-value, m은 해시 테이블 배열의 크기)를 고려해서 평균 시간 복잡도로 생각하는 것이 합리적이다
    - 이를 활용하여 계산하면, 탐색에 걸리는 평균 시간 복잡도는 O(1) 이다



### 추상 자료형

- 기능 vs 구현
  - 기능: 연산이 '무엇'을 하는지에 관한 내용
  - 구현: 연산의 기능을 '어떻게'할 지에 관한 내용
- 추상화
  - 구현을 몰라도 기능만 알면 해당 프로그램을 사용할 수 있게 만들어 놓는 것
  - 코드를 재활용하고 협력하는 데 용이함
  - ex) 리스트, 큐, 스택, 딕셔너리, 세트
- 추상 자료형
  - 자료 구조를 추상화 한 것
  - 데이터를 저장하고 사용할 때 기능만 생각하면 사용할 수 있게 만든 자료형
  - ex) 리스트(추상 자료형) - 동적 배열(자료 구조), 연결 리스트(자료 구조)
  - 추상 자료형을 생각하면 코드의 흐름에 집중할 수 있다
    - 필요한 기능만을 생각해서 추상 자료형을 생각한 후, 구체적으로 어떤 기능을 많이 사용하는 지 등의 기준에 따라 효율적인 자료 구조를 선택해서 이후에 구현하면 되는 것이다
    - ex) 리스트를 동적 배열 형태로 구현하면 접근 연산할 때 효율적이다. 더블리 링크드 리스트로 구현하면 맨 앞 삽입이나 맨 앞 삭제 연산할 때 효율적이다
- python의 deque는 내부적으로 더블리 링크드 리스트로 구현되어 있고, python의 list는 내부적으로 동적 배열로 구현되어 있다
- python dictionary는 내부적으로 해시 테이블을 사용해서 구현되어 있다
- python set는 내부적으로 해시 테이블을 사용해서 구현되어 있다. dictionary 에서는 해시 테이블에 key-value를 저장하지만 set는 key만 저장한다
- 어떤 자료형을 사용할 것인가? list vs set
  - 만약 탐색만을 생각한다면? set 쪽이 훨씬 빠르다. set은 해시 테이블을 사용하므로 O(1)이고 list는 O(n) 이니까
  - 하지만 set은 순서를 구현할 수 없으니 항상 set을 사용할 수는 없을 것이다. 상황에 맞는 자료형을 선택해야 한다. 해당 자료형이 어떤 자료 구조로 만들어져 있는지를 생각해서 효율적인 자료형을 선택해야 한다

